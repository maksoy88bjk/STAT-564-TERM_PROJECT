---
title: "Daily Rainfall Modelling in one of the automated-weather observation station in Mugla Province of Türkiye"
author: 
  - name: Mehmet AKSOY *(aksoy.mehmet@metu.edu.tr)*
    affiliations:
    - ref: metu
    - ref: civil
  - name: Sercan AKIL  *(sercan.akil@metu.edu.tr)*
    affiliations:
    - ref: metu
    - ref: ggit
  - name: Deniz Güvenç TEK  *(deniz.tek@metu.edu.tr)*
    affiliations:
    - ref: metu
    - ref: stat
affiliations:
  - id: metu
    name: Middle East Technical University, Ankara, Türkiye
  - id: civil
    name: Department of Civil Engineering
  - id: ggit
    name: Geodetic and Geographic Information Technologies
  - id: stat
    name: Department of Statistics
format: 
  html:
    editor: visual
    toc: true
    number-sections: true
bibliography: references.bib
---

# Introduction

Precipitation is one of the most important meteorological factors that have large impacts on human life and ecosystems worldwide in many ways such as freshwater, irrigation, hydropower production etc. As many authors have indicated that the nature of precipitation shows high variability in terms of both spatial and temporal scales [@domroes1998a; @f.2002a; @mitchell2005a]. Therefore, studies on precipitation are very considerable particularly taking into account of climate change effects.

Tree models are one of the most natural and popular method to model categorical response variables, even these methods can also be used to model continuous responses. In the literature there are many studies that are used tree-based models to predict precipitation amounts, fill the missing data and categorize precipitation types [@choubin2018; @kim2010; @englehart2009; @wei2019].

This study is focused on daily rainfall modelling for Muğla Province by using meteorological observations.

# Applications in R

### Uploading Necessary Packages

```{r}
#| warning: false
library(readxl)
library(tidyverse)
library(lubridate)
library(corrplot)
library(rnaturalearth)
library(sf)
library(ggplot2)
library(forecast)
library(tseries)
library(seasonal)
library(stats)
library(gridExtra)
library(grid)
library(glmnet)
library(ISLR)
library(plotmo)
library(MASS)
library(tree)
```

## Study Location & Data

In this study, Muğla Province is selected as study area where is located south western part of Turkey near the Mediterranean Sea. The meteorological station 17292 has been operated for providing climatic observations by Turkish State Meteorological Service. The figure below is shown for location of this station.

```{r, fig.width=9,fig.height=6}
#| warning: false
#| 
rnaturalearth::ne_countries(scale='medium',returnclass = 'sf') |> 
ggplot()  + geom_sf(fill = "white") +
  geom_point(aes(x=28.3668,y=37.2095),size=4) + labs(x="",y="") + 
  coord_sf(crs = st_crs(4326), xlim = c(23, 31), ylim = c(35,39)) + 
  theme_bw() + 
  theme(legend.position = "none",
        panel.background = element_rect(fill = 'aliceblue')) +
  annotate(geom="text", x=29, y=35.5, label="MEDITERRANEAN SEA", 
        color="cornflowerblue", fontface = "bold.italic", size=4) + 
  annotate(geom="text", x=30, y=38.5, label="TURKIYE", 
        color="darkgray", fontface = "bold.italic", size=4) +
  annotate(geom="text", x=23.1, y=38.4, label="GREECE", 
        color="darkgray", fontface = "bold.italic", size=4) + 
  annotate(geom="text", x=28.7, y=37.3, label="Mugla Station \n 17292", 
        color="black", fontface = "bold.italic", size=4)
```

### Data Handling

Data period is between 01.01.2009 and 31.12.2023 for Mugla Station (17292). Elevation of the station is 646 meter. Daily precipitation data is used as response variable in modelling. Distinct daily observation variables are used as predictors such as temperature (°C), dew point temperature (°C), sea-level air pressure (mb), cloud coverage (0-8), relative humidity (%), solar exposure (hour), solar radiation (W/m2) direction of wind (°) and speed (m/sec).

```{r}

files<- list.files(paste0(here::here(),"/DATA"), pattern = "xlsx")
listem<- list()
missdates<- list()

for(i in 1:length(files)) {

  listem[[i]] <- read_excel( paste0(here::here(),"/DATA/", files[i]))
  listem[[i]] <- listem[[i]][ ,-c(1,2)]

  listem[[i]]<-
    listem[[i]] |>
    mutate(DATE= as.Date(with(listem[[i]], paste(YEAR,MONTH,DAY,sep="-")),"%Y-%m-%d")) |>
    complete(DATE = seq(as.Date("2009-01-01"),
                         as.Date("2023-12-31"), by = "day"))
  listem[[i]] <- listem[[i]] [,-c(2:4)]
  missdates[[i]]<- listem[[i]][which(is.na(listem[[i]] [,2] )),]
}

df<- listem[[1]]
for(i in 1:(length(files)-1)) {
  df <- merge(df, listem[[i+1]], by = "DATE", all = TRUE)
}

write.table(df, "merge.txt", row.names = FALSE, quote = FALSE, sep = "\t")
```

### Descriptive Statistics

```{r}
#| warning: false

head(df)
summary(df)
```

### Visualization of the Data

```{r, fig.width=9,fig.height=9}
#| warning: false

paletr<- c("#053061", "#2166AC" ,"#4393C3" ,"#92C5DE" ,
           "#F4A582", "#D6604D" ,"#B2182B", "#67001F")
corrplot(round(cor(df[,2:18], method = "pearson", use = "complete.obs"),2), 
         method="color", col=paletr,  
         type="upper",  
         addCoef.col = "white", 
         tl.col="black",  insig = "blank", 
         diag=FALSE )
```

```{r, fig.width=9,fig.height=9}
#| warning: false

variable_names <- 
c("Precipitation", "Minimum_Temperature", "Maximum_Temperature", 
  "Average_Temperature", "Minimum_Dewpoint_Temperature", 
  "Maximum_Dewpoint_Temperature", "Average_Dewpoint_Temperature",
  "Minimum_Relative_Humidity", "Maximum_Relative_Humidity", 
  "Average_Relative_Humidity", "Cloudiness", "Air_Pressure", 
  "Average_Wind_Direction", "Average_Wind_Speed", 
  "Evapotranspiration", "Solar_Radiation", "Sun_Exposure")
colnames(df) <- append("Date", variable_names)

df_plot<-
df |>
  pivot_longer(
    cols = -c(1),
    values_drop_na = FALSE)
df_plot$name <- factor(df_plot$name, levels = colnames(df)[2:18])

ggplot(df_plot, aes(x= Date, y=value,color=name)) + 
  geom_line(size=0.1) + facet_wrap(~name, scales = "free_y", ncol=3) + 
  theme_bw() + labs(x=" ",y=" ") + 
  theme(legend.position = "none",
        strip.background = element_rect(fill="white")) 
```

```{r, fig.width=9,fig.height=9}
#| warning: false

ggplot(df_plot, aes(x= Date, y=value, fill=name, group=year(Date))) +
  geom_boxplot(outlier.shape = NA, alpha=0.7) + facet_wrap(~name, scales = "free_y", ncol=3) +
  theme_bw() + labs(x=" ",y=" ") +
  theme(legend.position = "none",
        strip.background = element_rect(fill="white")) 
```

## EDA of the Precipitation

### Missing Value

```{r}
#| warning: false
df_pre=df[,c(1,2)]
head(df_pre)

#Calculating the number of null values if there is one.

pre_null_values= sum(is.na(df_pre$Precipitation))
print(paste("Number of Null Values in Precipitation Column:",pre_null_values))
```

### Time Series Plot of the Precipitation Data

```{r}
#| warning: false
missing_date= df_pre$Date[is.na(df_pre$Precipitation)]
missing_date

#Time Series Plot of Precipitation (with Missing Data Highlighted (2009-2024)
ggplot(df_pre, aes(x = Date, y = Precipitation)) +
  geom_line(color = "red", size = 0.5,alpha=0.5) +  # Continuous line plot
  geom_smooth(method = "loess", se = FALSE, color = "orange", size = 1.5) +  #Trend line
  geom_point(aes(color = !is.na(Precipitation)), size = 1,alpha=0.5, shape = 21, fill = "white", show.legend = FALSE) +
  geom_text(data = subset(df_pre, is.na(Precipitation)), aes(label = "NA", y = 0), vjust = -0.5, color = "blue",size= 3) +  # Marking NAs
  scale_color_manual(values = c("black", "red")) +  # Red points for non-missing data
  labs(title = "Time Series Plot of Precipitation Data (2009-2024)",
       x = "Date",
       y = "Precipitation (mm)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(hjust = 0.5)) #Centering the title

#Time Series Plot of Precipitation (with Missing Data Highlighted (2021-2024)

df_pre_p1= filter(df_pre, Date>= as.Date("2021-01-01"))


ggplot(df_pre_p1, aes(x = Date, y = Precipitation)) +
  geom_line(color = "red", size = 1) +  # Plotting the precipitation data
  geom_point(aes(color = !is.na(Precipitation)), size = 2, shape = 21, fill = "white", show.legend = FALSE) +
  scale_color_manual(values = c("orange", "red")) +  # Use red points to mark non-missing data
  labs(title = "Time Series Plot of Precipitation Data (2021-2024)",
       x = "Date",
       y = "Precipitation (mm)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Improve readability of x-axis labels
```

According to the time series plot of the precipitation, there is no specific long-term trend (orange line) over the years. 4 of the 5 null values are found sequentially and one of them is located in "2012-11-09". The plot exhibits high volatility and also might be observed some seasonality (clearly observed in plot 2).

### Seasonality Analyze

```{r}
#| warning: false
#Seasonal Decomposition
#Mean Imputation for NA values
df_pre1=df_pre
mean_imput=mean(df_pre1$Precipitation,na.rm=TRUE)
df_pre1$Precipitation[is.na(df_pre1$Precipitation)]=mean_imput
df_pre_ts= ts(df_pre1$Precipitation, frequency = 365)
result_stl <- stl(df_pre_ts, s.window = "periodic")
plot(result_stl)
ljung_box_result= Box.test(df_pre1$Precipitation, lag= 365, type= "Ljung-Box")
print(ljung_box_result)
```

-   Ho: No auto correlation for lags=365

-   H1: Some auto correlation for lags=365

Since the p-value is less than 0.05 we suggest that there is some autocorrelation for lags=365 in Precipitation data which is a strong indication of seasonality. Also, we can clearly observe seasonality in the Seasonality Component plot.

### Stationarity Analyze

```{r}
#| warning: false
adf_test= adf.test(df_pre1$Precipitation, alternative = "stationary")
print(adf_test)
```

-   Ho: The time series is non-stationary

-   H1: The time series is stationary

Since our p-value is less than 0.05, it can be concluded that the time series is stationary. That means that the mean, variance and autocorrelation of the series do not change over the years. Since we satisfied the assumption of stationary we can perform Statistical Models as well as Machine Learning Approaches.

### Monthly Total Means

```{r, fig.width=9,fig.height=6}
#| warning: false

df |> 
  mutate(Month = month(Date), Year = year(Date)) |> 
  group_by(Month, Year) |> 
  summarize(TotalPrecipitation = sum(Precipitation, na.rm = TRUE), 
            .groups = 'drop') |> 
  group_by(Month) |> 
  summarize(MeanPrecipitation = mean(TotalPrecipitation, na.rm = TRUE), 
            .groups = 'drop') |> 
  ggplot(aes(x=factor(month.name, levels=month.name), 
             y=MeanPrecipitation, group = 1)) + 
  geom_bar(stat = "identity", fill = "skyblue", color="navyblue") + 
  labs(x = "Month", y = "Precipitation (mm)") + 
  geom_line(color = "navyblue", size = 1) + 
  geom_point(color = "navyblue", size = 2) + 
  theme_bw() + theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Ridge & Lasso Regularization

Hydrometeorologists measure time differently than the standard January to December calendar year. For those of us that model and track the movement of water through the landscape, the year begins on October 1st and ends on September 30th. This is known as a water year.

```{r}
#| warning: false
df_n<- 
 df |> 
  dplyr::select(!Evapotranspiration) |> 
  drop_na()  |> 
  filter(Date < "2023-01-01" ) 

df_n$Month<-ifelse(month(df_n$Date)>=10, 
                        month(df_n$Date)-9,
                        month(df_n$Date)+3) 

x<- model.matrix(Precipitation ~. , df_n )[,-c(1:2)]
y<- df_n$Precipitation

set.seed(1)
#train <- sample(1:nrow(x), nrow(x)*0.8)
#train <- seq(1:4419)
train <-  seq(1: nrow(df_n |>  filter(Date < "2021-01-01" ) ) ) 

#  RIDGE
grid <- 10^seq(10, -2, length=100)
ridge.mod <- glmnet(x[train,], y[train], alpha=0)

plot_glmnet(ridge.mod,label=8)

ridge.pred <- predict(ridge.mod, s=4, newx = x[-train,])
mean( (ridge.pred - y[-train])^2 )

# ten-fold cross-validation
set.seed(1)
cv.out <- cv.glmnet(x[train,], y[train], alpha=0)
plot(cv.out)
bestlambda <- cv.out$lambda.min ; bestlambda

ridge.pred <- predict(ridge.mod, s=bestlambda, newx = x[-train,])
mean( (ridge.pred - y[-train])^2 )

out<- glmnet(x[train,], y[train],alpha=0)
predict(out,type="coefficients",s=bestlambda)

pp<- predict(out, newx = x[-train,], type = "response", s=bestlambda)
pp2<- ifelse(pp < 0, 0, pp )

plot(y[-train], pp2)

# LASSO 

lasso.mod <- glmnet(x[train,],y[train], alpha=1)
plot_glmnet(lasso.mod,label=8)

set.seed(1)
cv.out=cv.glmnet(x[train ,],y[train],alpha=1)
plot(cv.out)
bestlam=cv.out$lambda.min ; bestlam

lasso.pred <- predict(lasso.mod, s=4, newx = x[-train,])
mean( (lasso.pred - y[-train])^2 )

lasso.pred=predict(lasso.mod,s=bestlam ,newx=x[-train,])
mean((lasso.pred-y[-train])^2)

out<- glmnet(x[train,], y[train],alpha=1)
predict(out,type="coefficients",s=bestlam)

pp_2<- predict(out, newx = x[-train,], type = "response", s=bestlam)
pp2_2<- ifelse(pp_2 < 0, 0, pp_2 )

plot(y[-train], pp2_2)

### deseasonalized <- seasadj(result_stl) ????
```

-   Ridge Regression

MSE score is found??77.69??with chosen best lambda??which??is 0.433. According to the plot of the relationship between lambda and coefficients, Average wind speed took the highest coefficient??which??means there is a strong relationship between precipitation. Also, we??penalized??each variable and average wind speed most to avoid bias and overfitting.??Anyway,??we get poor performance on Ridge regression by looking at the plot of actual and predicted values.??Since our precipitation exhibits non-linearity and??it??recognises??rainy days as??spikes??we should think about non-linear solutions like random forest, neural network??etc.

-   Lasso Regression

We get similar results when we compare with the results of Ridge regression. Unlike the usual, no variables shrunk towards zero.??This??means each variable is highly correlated and affects the predictor variable with the chosen??of??the optimal??lambda value. Because of??that??can't we use Lasso regression as a feature selection phase?

Do we need to scale both regreesion and revise the process?

## Fitting Regression Trees

```{r}
#| warning: false
df_tree<- df_n[,-1]
tree.precipitation <- tree(Precipitation~.,df_tree, subset=train)
summary(tree.precipitation)
```

Notice that the output of summary() indicates that only five of the variables have been used in constructing the tree. Relative humidity, air pressure and month variables become the most important ones, as we expected except cloudiness. In the context of a regression tree, the deviance is simply the sum of squared errors for the tree. We now plot the tree.

```{r, fig.width=9,fig.height=6}
#| warning: false
plot(tree.precipitation)
text(tree.precipitation,pretty=0)
```

Now we use the cv.tree() function to see whether pruning the tree will improve performance. K-fold cross validation technique is preformed to prune the regression tree. The minimum deviance is available where number of terminal nodes is 4. Thus, we can prune the regression tree from 10 to 4 terminal nodes.

```{r, fig.width=9,fig.height=5}
#| warning: false
set.seed(1)
cv.precipitation <- cv.tree(tree.precipitation);cv.precipitation
plot(cv.precipitation$size, cv.precipitation$dev,
     type='b', col="dodgerblue", lwd=2)
abline(v = which.min(rev(cv.precipitation$dev)), col="firebrick", lwd=2, lty=2)
```

In this case, the four-node tree is selected by cross-validation. Thus, we can prune the tree, we could do so as follows, using the prune.tree() function:

```{r, fig.width=9,fig.height=6}
#| warning: false
prune.precipitation <- prune.tree(tree.precipitation,best=4)
plot(prune.precipitation)
text(prune.precipitation,pretty=0)
```

In keeping with the cross-validation results, we use the unpruned tree to make predictions on the test set.

```{r, fig.width=9,fig.height=5}
#| warning: false

yhat <- predict(tree.precipitation,newdata=df_tree[-train,])
df_tree.test <- df_tree[-train,"Precipitation"]

plot_test<-
  data.frame(yhat, df_tree.test) |> 
  ggplot(aes(x= yhat, y=df_tree.test)) + 
  theme_bw() +
  geom_point(size=2, alpha=0.5, color="dodgerblue") + 
  geom_abline() + 
  labs(x="Predicted Response",y="True Response") + 
  annotate("text", x=60, y=20, label= 
             paste("MSE is",
             round(mean((yhat - df_tree.test)^2),2)))

plot_test
```

In other words, the test set MSE associated with the regression tree is `r round(mean((yhat - df_tree.test)^2),2)`. The square root of the MSE is therefore around `r round(sqrt(mean((yhat - df_tree.test)^2)),2)`, indicating that this model leads to test predictions that are within around `r round(sqrt(mean((yhat - df_tree.test)^2)),2)` mm of the true median precipitation value for the Mugla Station.

```{r}
yhat_prune <-predict(prune.precipitation,newdata=df_tree[-train,])
```

The MSE and RMSE for pruned tree are estimated as `r round(mean((yhat_prune - df_tree.test)^2),2)` and `r round(sqrt(mean((yhat_prune - df_tree.test)^2)),2)`, respectively. Due to the nature of regression trees the predictions equal to averages of response variables in training data based on embranchment of the tree. In our example, predictions are available for five and 4 variables for unpruned and pruned cases, respectively.

### Bagging and Random Forests

# Conclusion

Eshel and Farrell [@eshel2000] investigated rainfall variability over Eastern Mediterranean and they showed that rainfall is mostly depend on pressure anomalies. Lower air pressure is mostly related with precipitation since mostly frontal systems brings rainfall over Eastern Mediterranean. These frontal systems also means windy storms which comes from over Mediterranean Sea. Similarly, relative humidity is highly related with precipitation since rainfall formation is much easier in saturated air conditions. As everyone might guess cloud is necessary for rainfall production. By the way, dew point temperature means that how much air should be cooled to be saturated without any moisture addition. Thus, closer dew point temperature and air temperature means highly saturated and vice versa. As stated above, relative humidity, cloud coverage, air pressure, dew point temperature, wind direction, wind speed and temperature should be used as predictors while response is precipitation. However, only relative humidity, air pressure and wind direction parameters are used in our pruned trees. This situation most probably caused because of predictor’s correlation between each other. Correlation matrix of variables is given in Figure 11. As shown in the Figure, some variables are highly correlated with each other whether positive or negative. For example, correlation coefficient between cloud coverage and relative humidity is 0.7 and -0.6 between dew point temperature and air pressure. Thus, using many variables has become unnecessary.
