---
title: "Daily Rainfall Modelling in Mugla"
author: 
  - name: Mehmet AKSOY *(aksoy.mehmet@metu.edu.tr)*
    affiliations:
    - ref: metu
    - ref: civil
  - name: Sercan AKIL  *(sercan.akil@metu.edu.tr)*
    affiliations:
    - ref: metu
    - ref: ggit
  - name: Deniz GUVENC TEK  *(deniz.tek@metu.edu.tr)*
    affiliations:
    - ref: metu
    - ref: stat
affiliations:
  - id: metu
    name: Middle East Technical University, Ankara, Turkiye
  - id: civil
    name: Department of Civil Engineering
  - id: ggit
    name: Geodetic and Geographic Information Technologies
  - id: stat
    name: Department of Statistics
format: 
  html:
    editor: visual
    toc: true
    number-sections: true
bibliography: references.bib
---

::: callout-important
## Disclaimer

This document is a product of the final project for the STAT 564 lecture, focusing on statistical data analysis and machine learning models. It is essential to acknowledge that minor errors may be present, and the methods employed may not necessarily reflect the optimal approach related to the data set.
:::

# Introduction

Precipitation is one of the most important meteorological factors that have large impacts on human life and ecosystems worldwide in many ways such as freshwater, irrigation, hydropower production etc. As many authors have indicated that the nature of precipitation shows high variability in terms of both spatial and temporal scales [@domroes1998a; @f.2002a; @mitchell2005a]. Therefore, studies on precipitation are very considerable particularly taking into account of climate change effects.

While the ARIMA model is effective for many time series analyses, incorporating seasonality and exogenous variables can significantly enhance its predictive power. However, since ARIMA assumes the time series is stationary, it is necessary to employ a different model for non-stationary data with seasonal patterns.

This is where the SARIMA (Seasonal ARIMA) model comes into play. Similar to the ARIMA model, SARIMA includes additional seasonal autoregressive and moving average components. These seasonal lags correspond to the periodicity of the data (e.g., 12 for monthly data, 24 for hourly data).

SARIMA models facilitate differencing by both seasonal and non-seasonal frequencies[@kim2010]. Identifying the optimal parameters can be streamlined using automated parameter search frameworks such as pmdarima.

Tree decision models are one of the most natural and popular method to model categorical response variables, even these methods can also be used to model continuous responses. In the literature there are many studies that are used tree-based models to predict precipitation amounts, fill the missing data and categorize precipitation types [@choubin2018; @kim2010; @englehart2009; @wei2019].

Regularization is a technique used to prevent overfitting in statistical models by adding a penalty to the model complexity. In the context of regression models, shrinkage methods are a form of regularization that reduce the size of the coefficients towards zero, effectively shrinking them. This can enhance the model's generalization to new data by avoiding overfitting.

Two common shrinkage methods are:

1.  **Ridge Regression (L2 regularization)**: Adds a penalty equal to the sum of the squared coefficients.

2.  **Lasso Regression (L1 regularization)**: Adds a penalty equal to the sum of the absolute values of the coefficients.

The SARIMA (Seasonal Autoregressive Integrated Moving Average) model is a powerful tool for time series forecasting that accounts for both non-seasonal and seasonal components. While SARIMA itself does not directly incorporate regularization methods like those used in regression, regularization can be applied in the context of model selection and parameter estimation to enhance the model's performance.

**Regularization in SARIMA**:

-   **Parameter Selection**: Automated frameworks such as pmdarima use regularization principles to optimize the selection of SARIMA parameters (p, d, q, P, D, Q, and s). These frameworks often employ criteria like the Akaike Information Criterion (AIC) or Bayesian Information Criterion (BIC), which inherently penalize model complexity to prevent over fitting.

-   **Ensemble Methods**: Combining multiple SARIMA models with regularization techniques can help in stabilizing the predictions and improving the robustness of the model.

**Tree Models and Regularization**

Tree-based models, including Decision Trees, Random Forests, and Gradient Boosting Machines (GBMs), can benefit from regularization techniques to improve their performance and prevent overfitting.

**Regularization in Tree Models**:

1.  **Pruning (for Decision Trees)**:

    -   Reduces the size of the tree by removing sections that provide little power in predicting target variables.

    -   Can be achieved through cost-complexity pruning which penalizes the tree for having too many branches.

2.  **Hyperparameter Tuning**:

    -   **Max Depth**: Limiting the depth of the tree to prevent it from growing too complex.

    -   **Min Samples Split**: The minimum number of samples required to split an internal node.

    -   **Min Samples Leaf**: The minimum number of samples required to be at a leaf node.

3.  **Ensemble Methods**:

    -   **Random Forests**: Aggregate the predictions of multiple decision trees, reducing overfitting through averaging.

    -   **Gradient Boosting**: Sequentially builds trees, where each new tree tries to correct the errors of the previous ones. Regularization in GBM can include:

        -   **Learning Rate**: Controls the contribution of each tree.

        -   **Subsampling**: Uses a subset of data for training each tree.

        -   **L1 and L2 Regularization**: Adds penalties for the complexity of the model.

4.  **Regularization Parameters in Gradient Boosting**:

    -   **Shrinkage**: Similar to the learning rate, it scales the contribution of each tree added to the model.

    -   **Column Subsampling**: Reduces overfitting by randomly selecting a subset of features for each tree.

This study is focused on daily rainfall modelling for Mugla Province by using meteorological observations.

# Preliminary Preparations

### Uploading Necessary Packages

```{r}
#| warning: false
library(readxl)
library(tidyverse)
library(lubridate)
library(corrplot)
library(rnaturalearth)
library(rnaturalearthdata)
library(sf)
library(ggplot2)
library(forecast)
library(tseries)
library(seasonal)
library(stats)
library(gridExtra)
library(grid)
library(glmnet)
library(ISLR)
library(plotmo)
library(MASS)
library(tree)
library(randomForest)
library(gbm)
library(VIM)
library(mice)
library(Metrics)
library(caret)
library(e1071)
library(kernlab)
library(gt)
```

## Study Location & Data

In this study, Mugla Province is selected as the study area. This province is located in the southwestern part of Turkey, adjacent to the Mediterranean Sea, and is characterized by a Mediterranean climate with hot, dry summers and mild, wet winters. Mugla's diverse topography, ranging from coastal areas to mountainous regions, makes it an ideal location for climatic and hydrologic studies.

The meteorological station 17292, situated within Mugla Province, is operated by the Turkish State Meteorological Service (TSMS). This station has been consistently providing reliable climatic observations, including temperature, precipitation, humidity, and wind speed data, which are essential for understanding the local climate patterns and trends. The data collected from this station play a crucial role in various research studies, particularly those related to water resources management, agricultural planning, and climate change impact assessments in the region.

The figure below illustrates the precise location of meteorological station 17292 within Mugla Province. This visual representation aids in contextualizing the spatial distribution of climatic data collected and emphasizes the station's strategic position for capturing representative climatic information for the entire province.

```{r, fig.width=9,fig.height=6}
#| warning: false
#| 
rnaturalearth::ne_countries(scale='medium',returnclass = 'sf') |> 
ggplot()  + geom_sf(fill = "white") +
  geom_point(aes(x=28.3668,y=37.2095),size=4) + labs(x="",y="") + 
  coord_sf(crs = st_crs(4326), xlim = c(23, 31), ylim = c(35,39)) + 
  theme_bw() + 
  theme(legend.position = "none",
        panel.background = element_rect(fill = 'aliceblue')) +
  annotate(geom="text", x=29, y=35.5, label="MEDITERRANEAN SEA", 
        color="cornflowerblue", fontface = "bold.italic", size=4) + 
  annotate(geom="text", x=30, y=38.5, label="TURKIYE", 
        color="darkgray", fontface = "bold.italic", size=4) +
  annotate(geom="text", x=23.1, y=38.4, label="GREECE", 
        color="darkgray", fontface = "bold.italic", size=4) + 
  annotate(geom="text", x=28.7, y=37.3, label="Mugla Station \n 17292", 
        color="black", fontface = "bold.italic", size=4)
```

### Data Handling

Data period is between 01.01.2009 and 31.12.2023 for Mugla Station (17292). Elevation of the station is 646 meter. Daily precipitation data is used as response variable in modelling. Distinct daily observation variables are used as predictors such as temperature (C°), dew point temperature (C°), sea-level air pressure (mb), cloud coverage (0-8), relative humidity (%), solar exposure (hour), solar radiation (W/m^2^) direction of wind (B0) and speed (m/sec).

```{r}
#| warning: false
files<- list.files(paste0(here::here(),"/DATA"), pattern = "xlsx")
listem<- list()
missdates<- list()

for(i in 1:length(files)) {

  listem[[i]] <- read_excel( paste0(here::here(),"/DATA/", files[i]))
  listem[[i]] <- listem[[i]][ ,-c(1,2)]

  listem[[i]]<-
    listem[[i]] |>
    mutate(DATE= as.Date(with(listem[[i]], paste(YEAR,MONTH,DAY,sep="-")),"%Y-%m-%d")) |>
    tidyr::complete(DATE = seq(as.Date("2009-01-01"),
                         as.Date("2023-12-31"), by = "day"))
  listem[[i]] <- listem[[i]] [,-c(2:4)]
  missdates[[i]]<- listem[[i]][which(is.na(listem[[i]] [,2] )),]
}

df<- listem[[1]]
for(i in 1:(length(files)-1)) {
  df <- merge(df, listem[[i+1]], by = "DATE", all = TRUE)
}

write.table(df, "merge.txt", row.names = FALSE, quote = FALSE, sep = "\t")
```

# Descriptive Statistics

1.  **Precipitation**: This is any form of water - liquid or solid - that falls from the atmosphere and reaches the ground. It includes rain, snow, sleet, and hail. It is usually measured in millimeters (mm).

    -   Most days experience less precipitation, but there are occasional instances of heavy rainfall, with a maximum of 168.6 mm.

2.  **Temperature**: This is a measure of the warmth or coldness of the atmosphere as determined by a thermometer. It is typically reported in degrees Celsius.

    -   The temperature ranges from cold to hot conditions, with mean temperatures around 10-15 C° and maximum temperatures reaching as high as 41.7.

3.  **Dew Point Temperature**: This is the temperature at which air becomes saturated with moisture and dew can form. It is an indicator of the moisture content in the air and is measured in degrees Celsius.

    -   Dewpoint temperatures indicate varying levels of atmospheric moisture, ranging from dry to humid conditions with maximum 19.9 C°.

4.  **Relative Humidity**: This is the amount of moisture in the air compared to what the air can hold at that temperature. It is expressed as a percentage (%).

    -   Relative humidity values show a wide range of humidity levels, from very dry to highly moist air.

5.  **Cloudiness**: This refers to the extent of cloud cover in the sky or in descriptive terms such as clear, partly cloudy, mostly cloudy, or overcast.

    -   Cloudiness varies from clear to cloudy days, with a mean cloudiness value suggesting moderate cloud cover.

6.  **Wind Speed**: This measures how fast the air is moving. It is typically reported in meters per second (m/s), kilometers per hour (km/h).

    -   Wind speeds are generally low, with occasional higher speeds recorded with 4.70 m/s.

7.  **Wind Direction**: This indicates the direction from which the wind is blowing. It is usually expressed in degrees from true north or using compass directions (e.g., N, NE, E).

    -   **NA's (Missing Values)**: 111

    -   These statistics indicate the average, middle, minimum, and maximum wind directions recorded in the dataset, measured in degrees from true north. The presence of missing values (NA's) suggests that wind direction data is unavailable for some observations.

8.  **Evapotranspiration**: This is the sum of evaporation from the land surface plus transpiration from plants. It represents the amount of water transferred from the land to the atmosphere. It is usually measured in millimeters (mm).

    -   Evapotranspiration rates vary, reflecting differences in water loss from soil and plants.

9.  **Solar Radiation**: This is the energy from the sun received at the Earth's surface. It is typically measured in watts per square meter (W/m^2^).

    -   Solar radiation fluctuates, affecting temperature and other weather parameters.

10. **Sun Exposure**: This refers to the duration and intensity of sunlight reaching a particular area. It is often measured in hours per day.

    -   Sun exposure varies, reflecting differences in daylight duration with 12.2 hours maximum duration.

11. **Pressure**: This is the force exerted by the atmosphere at a given point. It is usually measured in hectopascals (hPa) or millibars (mb).

Sea level pressure typically ranges around 1013.25 hectopascals (hPa) or millibars (mb), which is considered the standard atmospheric pressure at sea level. However, actual sea level pressure can vary depending on weather conditions:

-   **High Pressure Systems**: These are usually associated with calm and fair weather. Sea level pressures in high-pressure systems typically range from about 1015 hPa to over 1040 hPa.
-   **Low Pressure Systems**: These are associated with stormy and unsettled weather. Sea level pressures in low-pressure systems can drop below 1000 hPa, and in severe storms like hurricanes or typhoons, pressures can drop significantly lower, sometimes reaching around 950 hPa or even lower.
    -   Maximum: 1033.5 hPa
    -   Air pressure values fall within typical sea-level pressure ranges, indicating relatively stable atmospheric conditions.

```{r}
#| warning: false
print(paste("Number of Rows: ", nrow(df)))
print(paste("Number of Columns: ", ncol(df)))
head(df)
summary(df)
```

### Visualization of the Data

As stated above, relative humidity and cloud coverage should be used as predictors while response is precipitation since the relationship is higher than other variables. However, predictor's correlation between each other is also high whether positively or negatively. For example, correlation coefficient between cloud coverage and relative humidity is 0.67 or between maximum relative humidity and solar radiation is 0.72. This situation will most likely result in not needing to use many variables.

In the second part, it can be seen data deficient especially for evapotranspiration. Missing data imputation has been evaluated. However, in terms of technical approach this has been ignored. The other aspect is seasonality the data experiences regular and predictable changes recur. The temporal variability associated with seasonal patterns, such as temperature fluctuations, precipitation trends, and solar radiation changes, necessitates careful consideration during data analysis and interpretation. This can be explained climatic conditions of the station.

```{r, fig.width=9,fig.height=9}
#| warning: false

paletr<- c("#053061", "#2166AC" ,"#4393C3" ,"#92C5DE" ,
           "#F4A582", "#D6604D" ,"#B2182B", "#67001F")
corrplot(round(cor(df[,2:18], method = "pearson", use = "complete.obs"),2), 
         method="color", col=paletr,  
         type="upper",  
         addCoef.col = "white", 
         tl.col="black",  insig = "blank", 
         diag=FALSE )
```

```{r, fig.width=9,fig.height=9}
#| warning: false

variable_names <- 
c("Precipitation", "Minimum_Temperature", "Maximum_Temperature", 
  "Average_Temperature", "Minimum_Dewpoint_Temperature", 
  "Maximum_Dewpoint_Temperature", "Average_Dewpoint_Temperature",
  "Minimum_Relative_Humidity", "Maximum_Relative_Humidity", 
  "Average_Relative_Humidity", "Cloudiness", "Air_Pressure", 
  "Average_Wind_Direction", "Average_Wind_Speed", 
  "Evapotranspiration", "Solar_Radiation", "Sun_Exposure")
colnames(df) <- append("Date", variable_names)

df_plot<-
df |>
  pivot_longer(
    cols = -c(1),
    values_drop_na = FALSE)
df_plot$name <- factor(df_plot$name, levels = colnames(df)[2:18])

ggplot(df_plot, aes(x= Date, y=value,color=name)) + 
  geom_line(size=0.1) + facet_wrap(~name, scales = "free_y", ncol=3) + 
  theme_bw() + labs(x=" ",y=" ") + 
  theme(legend.position = "none",
        strip.background = element_rect(fill="white")) 
```

```{r, fig.width=9,fig.height=9}
#| warning: false

ggplot(df_plot, aes(x= Date, y=value, fill=name, group=year(Date))) +
  geom_boxplot(outlier.shape = NA, alpha=0.7) + facet_wrap(~name, scales = "free_y", ncol=3) +
  theme_bw() + labs(x=" ",y=" ") +
  theme(legend.position = "none",
        strip.background = element_rect(fill="white")) 
```

### Monthly Total Means

Hydrologists use a different time measurement compared to the traditional January-to-December calendar year. For those who model and monitor water movement in the environment, the year starts on October 1st and concludes on September 30th.

This period is referred to as a water year. To better understand the numbering system, each month is assigned a numerical value starting from the beginning of the water year. The water year commences in October, thus October is designated as month 1. Consequently, subsequent months follow this sequence, with January being represented as month 4.

```{r, fig.width=9,fig.height=5}
#| warning: false

df |> 
  mutate(Month = month(Date), Year = year(Date)) |> 
  group_by(Month, Year) |> 
  summarize(TotalPrecipitation = sum(Precipitation, na.rm = TRUE), 
            .groups = 'drop') |> 
  group_by(Month) |> 
  summarize(MeanPrecipitation = mean(TotalPrecipitation, na.rm = TRUE), 
            .groups = 'drop') |> 
  ggplot(aes(x=factor(month.name, levels=month.name), 
             y=MeanPrecipitation, group = 1)) + 
  geom_bar(stat = "identity", fill = "skyblue", color="navyblue") + 
  labs(x = "Month", y = "Precipitation (mm)") + 
  geom_line(color = "navyblue", size = 1) + 
  geom_point(color = "navyblue", size = 2) + 
  theme_bw() + theme(axis.text.x = element_text(angle = 45, hjust = 1))


df |> 
  mutate(Month = month(Date), Year = year(Date)) |> 
  group_by(Month, Year) |> 
  summarize(TotalPrecipitation = sum(Precipitation, na.rm = TRUE), 
            .groups = 'drop') |> 
  arrange(Year, Month) |> 
  ggplot( aes(x = factor(Month, levels = 1:12, labels = month.name), 
               y = TotalPrecipitation, color = factor(Year), group = Year)) +
  geom_line() +  guides(color=guide_legend(title="Years")) +
  labs(x = "Month", y = "Precipitation (mm)") + 
  theme_bw() + theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Exploratory Data Analysis (EDA) of the Precipitation

### Missing Value

```{r}
#| warning: false
df_pre=df[,c(1,2)]
head(df_pre)

#Calculating the number of null values if there is one.

pre_null_values= sum(is.na(df_pre$Precipitation))
print(paste("Number of Null Values in Precipitation Column:",pre_null_values))
```

### Time Series Plot of the Precipitation Data

```{r}
#| warning: false
missing_date= df_pre$Date[is.na(df_pre$Precipitation)]
missing_date

#Time Series Plot of Precipitation (with Missing Data Highlighted (2009-2024))
ggplot(df_pre, aes(x = Date, y = Precipitation)) +
  geom_line(color = "red", size = 0.5,alpha=0.5) +  # Continuous line plot
  geom_smooth(method = "loess", se = FALSE, color = "orange", size = 1.5) +  #Trend line
  geom_point(aes(color = !is.na(Precipitation)), size = 1,alpha=0.5, shape = 21, fill = "white", show.legend = FALSE) +
  geom_text(data = subset(df_pre, is.na(Precipitation)), aes(label = "NA", y = 0), vjust = -0.5, color = "blue",size= 3) +  # Marking NAs
  scale_color_manual(values = c("black", "red")) +  # Red points for non-missing data
  labs(title = "Time Series Plot of Precipitation Data (2009-2024)",
       x = "Date",
       y = "Precipitation (mm)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        plot.title = element_text(hjust = 0.5)) #Centering the title

#Time Series Plot of Precipitation (with Trend Line Highlighted (2021-2024))
df_pre_p1= filter(df_pre, Date>= as.Date("2021-01-01"))

ggplot(df_pre_p1, aes(x = Date, y = Precipitation)) +
  geom_line(color = "red", size = 1) +  # Plotting the precipitation data
  geom_point(aes(color = !is.na(Precipitation)), size = 2, shape = 21, fill = "white", show.legend = FALSE) +
  scale_color_manual(values = c("orange", "red")) +  # Use red points to mark non-missing data
  labs(title = "Time Series Plot of Precipitation Data (2021-2024)",
       x = "Date",
       y = "Precipitation (mm)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Improve readability of x-axis labels
```

According to the time series plot of the precipitation, there is no specific long-term trend (orange line) over the years. 4 of the 5 null values are found sequentially and one of them is located in "2012-11-09". The plot exhibits high volatility and also might be observed some seasonality (clearly observed in plot 2).

# Methodology

## MICE Imputation

In the precipitation time series data, there is some null values in various of precipitation and other predictor variables. Since majority of the input values in Evapotranspiration consist of null values, we remove that variable. After that, there is approximately 8% of null values left in the data. Although various of imputation techniques have been utilized, there was no significant difference compared to dropping null values. The possible reason for that the response variable (precipitation) usually contains the value of 0 or has seasonality in all predictor variables. After multiple tries, MICE imputation with 5 imputed datasets and 50 iterations gets the highest difference then adapted in the imputation part.

```{r}
#| warning: false
df_null=df %>% filter(Date < "2023-01-01" ) 
df_null1=apply(df_null,2,function(x) sum(is.na(x)))
df_null1
```

## Ridge & Lasso Regularization

Ridge regression is implemented in the glmnet R package. glmnet() function fits a generalized linear model via penalized maximum likelihood. In addition to this, the alpha argument is known as a mixing parameter, with the range of 0 and 1.

If alpha value equal to 0 the penalty term corresponds to the ridge regularized regression.

MSE score is found 77.69 with chosen best lambda which is 0.433. According to the plot of the relationship between lambda and coefficients, Average wind speed took the highest coefficient which means there is a strong relationship between precipitation.

Also, we penalized each variable and average wind speed most to avoid bias and overfitting. Poor performance on Ridge regression by looking at the plot of actual and predicted values. Since our precipitation exhibits non-linearity and it recognises rainy days as spikes we should think about non-linear solutions like random forest, neural network etc.

In lasso regression We get similar results when we compare with the results of Ridge regression. Unlike the usual, no variables shrunk towards zero. This means each variable is highly correlated and affects the predictor variable with the chosen of the optimal lambda value. Because of that we cannot use Lasso regression as a feature selection phase

```{r, message=FALSE}
#| warning: false

df_n<- 
 df |> 
  dplyr::select(!Evapotranspiration) |> 
  filter(Date < "2023-01-01" ) 

invisible(capture.output({
  suppressMessages({
    suppressWarnings({
      imputed_data=  mice(df_n, m =5, maxit =50, method ='pmm', seed =500)
      df_n <- complete(imputed_data)
    })
  })
}))

df_n$Month<-ifelse(month(df_n$Date)>=10, 
                        month(df_n$Date)-9,
                        month(df_n$Date)+3) 

x<- model.matrix(Precipitation ~. , df_n )[,-c(1:2)]
y<- df_n$Precipitation

set.seed(1)
train <-  seq(1: nrow(df_n |>  filter(Date < "2021-01-01" ) ) ) 

# rsquare
rsq <- function (x, y) round(cor(x, y) ^ 2, 2)

#  RIDGE
grid <- 10^seq(10, -2, length=100)
ridge.mod <- glmnet(x[train,], y[train], alpha=0)

plot_glmnet(ridge.mod,label=8)
ridge.pred <- predict(ridge.mod, s=4, newx = x[-train,])
mse_ridge= mse(ridge.pred, y[-train])
rmse_ridge= rmse(ridge.pred, y[-train])
smape_ridge= smape(ridge.pred, y[-train])
r2_ridge= rsq(as.numeric(ridge.pred), as.numeric(y[-train]))

# ten-fold cross-validation
set.seed(1)
cv.out <- cv.glmnet(x[train,], y[train], alpha=0)
plot(cv.out)
bestlambda <- cv.out$lambda.min ; bestlambda

ridge.pred <- predict(ridge.mod, s=bestlambda, newx = x[-train,])
mse_cv.ridge= mse(ridge.pred, y[-train])
rmse_cv.ridge= rmse(ridge.pred, y[-train])
smape_cv.ridge= smape(ridge.pred, y[-train])
r2_cv.ridge= rsq(as.numeric(ridge.pred), as.numeric(y[-train]))

out<- glmnet(x[train,], y[train],alpha=0)
predict(out,type="coefficients",s=bestlambda)
pp<- predict(out, newx = x[-train,], type = "response", s=bestlambda)
pp2<- ifelse(pp < 0, 0, pp ) ## eksi tahminleri sifira esitledik

plot(y[-train], pp2)

# LASSO 

lasso.mod <- glmnet(x[train,],y[train], alpha=1)
plot_glmnet(lasso.mod,label=8)

set.seed(1)
cv.out=cv.glmnet(x[train ,],y[train],alpha=1)
plot(cv.out)
bestlam=cv.out$lambda.min ; bestlam

lasso.pred <- predict(lasso.mod, s=4, newx = x[-train,])
mse_lasso= mse(lasso.pred, y[-train])
rmse_lasso= rmse(lasso.pred, y[-train])
smape_lasso= smape(lasso.pred, y[-train])
r2_lasso= rsq(as.numeric(lasso.pred), as.numeric(y[-train]))

lasso.pred=predict(lasso.mod,s=bestlam ,newx=x[-train,])
mse_cv.lasso= mse(lasso.pred, y[-train])
rmse_cv.lasso= rmse(lasso.pred, y[-train])
smape_cv.lasso= smape(lasso.pred, y[-train])
r2_cv.lasso= rsq(as.numeric(lasso.pred), as.numeric(y[-train]))

out<- glmnet(x[train,], y[train],alpha=1)
predict(out,type="coefficients",s=bestlam)

pp_2<- predict(out, newx = x[-train,], type = "response", s=bestlam)
pp2_2<- ifelse(pp_2 < 0, 0, pp_2 )

plot(y[-train], pp2_2)
```

-   Ridge Regression

MSE score is found 77.69 with chosen best lambda which is 0.433. According to the plot of the relationship between lambda and coefficients, Average wind speed took the highest coefficient which means there is a strong relationship between precipitation. Also, we penalized each variable and average wind speed most to avoid bias and overfitting. Anyway, we get moderately poor performance on Ridge regression by looking at the plot of actual and predicted values.Since our precipitation exhibits non-linearity and it recognises rainy days as spikes we should think about non-linear solutions like random forest, neural network etc.

-   Lasso Regression

We get similar results when we compare with the results of Ridge regression. Unlike the usual, no variables shrunk towards zero. This means each variable is highly correlated and affects the predictor variable with the chosen of the optimal lambda value. As a result, non of the predictor variables shrunk towards to 0.

## SARIMA & SARIMAX

### Seasonality Analyze

-   Ho: No auto correlation for lags=365

-   H1: Some auto correlation for lags=365

Since the p-value is less than 0.05 we suggest that there is some autocorrelation for lags=365 in Precipitation data which is a strong indication of seasonality. Also, we can clearly observe seasonality in the Seasonality Component plot.

On the other hand, when we examine the decomposition plot, there is still noise in the remainder part due to the possibility of recipient or weather variations. Also, there is a steady trend with some clear fluctuations as expected.

```{r}
#| warning: false

#Seasonal Decomposition
#Mean Imputation for NA values
df_pre_ts= ts(df_n$Precipitation, frequency = 365)
result_stl <- stl(df_pre_ts, s.window = "periodic")
plot(result_stl)
ljung_box_result= Box.test(df_n$Precipitation, lag= 365, type= "Ljung-Box")
print(ljung_box_result)
```

### Stationarity Analyze

-   Ho: The time series is non-stationary

-   H1: The time series is stationary

Since our p-value is less than 0.05, it can be concluded that the time series is stationary. That means that the mean, variance and autocorrelation of the series do not change over the years. Since we satisfied the assumption of stationary we can perform Statistical Models as well as Machine Learning Approaches.

```{r}
#| warning: false
adf_test= adf.test(df_n$Precipitation, alternative = "stationary")
print(adf_test)
```

### ACF & PACF Plots

```{r}
#| warning: false
par(mfrow = c(1, 2))
acf(df_n$Precipitation, main="ACF of Precipitation")
pacf(df_n$Precipitation, main="PACF of Precipitation")
```

Both of the ACF and PACF plots demonstrate significant spikes at lag 1. It can be observed that there is a repeated pattern in the ACF plot which is an indication of the seasonality. As a result, we should take seasonal differencing and there is no need for first-order differencing since our data is already in the stationary form.

```{r}
#| warning: false
df_n_diff= diff(df_n$Precipitation, lag=365)

par(mfrow = c(1, 2))
acf(df_n_diff, main="ACF of Precipitation")
pacf(df_n_diff, main="PACF of Precipitation")
```

After utilizing seasonal differencing we seem to have solved seasonality problem since all of the repeated lags remain in the white noise band. Therefore we can build SARIMA model with (1,0,1), (1,1,1,365).

```{r}
#| warning: false
#SARIMA MODEL
df_n_res= ts(df_n$Precipitation, frequency = 365)

sarima_model= Arima(y[train], 
                       order= c(1, 0, 1), 
                       seasonal= c(1, 1, 1, 365))

#summary(sarima_model)

sarima_forecast= forecast(sarima_model, h= length(y[-train]))
plot(sarima_forecast)

#Since precipitation cannot be non negative value, replaces those value with 0.
y_hat_sarima= sarima_forecast$mean
y_hat_sarima1=ifelse(y_hat_sarima<0,1e-6,y_hat_sarima)
y_act= y[-train]

mse_sarima= mse(y_act, y_hat_sarima)
rmse_sarima= rmse(y_act, y_hat_sarima)
smape_sarima= smape(y_act, y_hat_sarima1)
r2_sarima= rsq(y_act, y_hat_sarima)

print(paste("MSE of the SARIMAX Model: ", round(mse_sarima,2)))
print(paste("RMSE of the SARIMA Model: ", round(rmse_sarima,2)))
print(paste("SMAPE of the SARIMA Model: ", round(smape_sarima,2)))

```

```{r}
#| warning: false
#SARIMAX Model
sarimax_model= Arima(y[train], 
                       order= c(1, 0, 1), 
                       seasonal= c(1, 1, 1, 365), 
                       xreg= x[train,])

summary(sarimax_model)

sarimax_forecast= forecast(sarimax_model, h= length(y[-train]), xreg = x[-train,])
plot(sarimax_forecast)

#Since precipitation cannot be non negative value, replaces those value with 0.
y_hat_sarimax= sarimax_forecast$mean
y_hat_sarimax1=ifelse(y_hat_sarimax<0,1e-6,y_hat_sarimax)
y_act= y[-train]

mse_sarimax= mse(y_act, y_hat_sarimax)
rmse_sarimax= rmse(y_act, y_hat_sarimax)
smape_sarimax= smape(y_act, y_hat_sarimax1)
r2_sarimax= rsq(y_act, y_hat_sarimax)

print(paste("MSE of the SARIMAX Model: ", round(mse_sarimax,2)))
print(paste("RMSE of the SARIMAX Model: ", round(rmse_sarimax,2)))
print(paste("SMAPE of the SARIMAX Model: ", round(smape_sarimax,2)))

data.frame(Date = c(df_n$Date, df_n$Date),
                      Precipitation = c(y, 
                                append(rep(NA,length(train)), y_hat_sarimax1)),
                      Type = rep(c("Actual", "Predicted"), 
                                 each = length(df_n$Date))) |> 
ggplot(aes(x = Date, y = Precipitation, color = Type)) + 
  geom_line() +
theme_bw() +
scale_color_manual(name=" ",values = c("Actual" = "dodgerblue",
                              "Predicted" = "firebrick"),
                   labels = c("Actual", "Forecasts")) +
labs(x="Date",y="Precipitation (mm)") + 
  theme(legend.position = c(.9,.8)) +ggtitle("Forecasts of Precipitation by using SARIMAX Model")

```

According to the results, SARIMAX (with predictor variables) demonstrates fine results by looking at their MSE, RMSE and MAPE. On the other hand, SARIMA exhibits poor performance and their R\^2 is near 0. This can be understandable in the context of precipitation, where factors like wind speed, temperature and humidity directly affect the response variable. This strong relationship can be also analyzed by looking at the results of Lasso. Ignoring these factors, precipitation tends to consist of lots of zero values and other values appear as spikes. This makes it insufficient to understand by looking solely at the response variable. According to the forecast plot, SARIMAX generally captures the actual values except for values with higher precipitations.

```{r}
#| warning: false
residuals_sarimax <- residuals(sarimax_model)

# Plot of Residuals
ggplot(data = data.frame(Date= df_n$Date[train], Residuals= residuals_sarimax), aes(x= Date, y= Residuals)) +
  geom_line()+
  theme_bw()+
  labs(title ="Residuals of SARIMAX Model", x ="Date", y ="Residuals")

# Q-Q grafi??i
qqnorm(residuals_sarimax)
qqline(residuals_sarimax)
```

Before completing the SARIMAX modelling, the assumption of residuals of heteroscedasticity and normality. According to the plots, there is no sign of increasing variance. Although residuals are distributed a little bit heavier, it is acceptable because of the nature of the precipitation values.

## Support Vector Regression

```{r}
#| warning: false
df_n_lag= data.frame(Date = df_n$Date, y = y) %>% mutate(Lag1 = lag(y, 1), Lag7 = lag(y, 7)) %>% na.omit()
x_lag=x[-(1:7), ]
df_n_lag_c= cbind(df_n_lag, x_lag)
df_n_lag_c1= df_n_lag_c[!names(df) %in% c("Date")]
# Fit the SVR model
svr_model <- train(y ~ ., data = df_n_lag_c1[train,], method = "svmRadial", 
                   trControl = trainControl(method = "cv", number = 5),
                   preProcess = c("center", "scale"))


svr_forecasts <- predict(svr_model, newdata = df_n_lag_c1[-train,])

# Evaluate the model performance
mse_svr= mse(svr_forecasts, df_n_lag_c1$y[-train])
rmse_svr= rmse(svr_forecasts, df_n_lag_c1$y[-train])
smape_svr= smape(svr_forecasts, df_n_lag_c1$y[-train])
r2_svr= rsq(svr_forecasts, df_n_lag_c1$y[-train])

print(paste("MSE of the SVR Model: ", round(mse_svr,2)))
print(paste("RMSE of the SVR Model: ", round(rmse_svr,2)))
print(paste("SMAPE of the SVR Model: ", round(smape_svr,2)))

data.frame(Date = c(df_n_lag $Date, df_n_lag $Date),
                      Precipitation = c(df_n_lag$y, 
                                append(rep(NA,length(train)), svr_forecasts)),
                      Type = rep(c("Actual", "Predicted"), 
                                 each = length(df_n_lag$Date))) |> 
ggplot(aes(x = Date, y = Precipitation, color = Type)) + 
  geom_line() +
theme_bw() +
scale_color_manual(name=" ",values = c("Actual" = "dodgerblue",
                              "Predicted" = "firebrick"),
                   labels = c("Actual", "Predicted")) +
labs(x="Date",y="Precipitation (mm)") + 
  theme(legend.position = c(.9,.8)) +ggtitle("Prediction of Precipitation by using SVR Model")

```

SVR is also implemented in the dataset. The model is constructed with a 5-fold cross-validation and radial method by using scaled and centered data. Also, 1 day and 7 days lagged are added as a factor to get better results. According to the results we get similar results compared to SARIMAX. SVR also generally captures the trend and seasonal variation but not wells in the values with the higher magnitudes.

## Tree-Based Methods

### Fitting Regression

```{r}
#| warning: false
df_tree<- df_n[,-1]
set.seed(1)
tree.precipitation <- tree(Precipitation~.,df_tree, subset=train)
summary(tree.precipitation)
```

Notice that the output of summary() indicates that only seven of the variables have been used in constructing the tree. Relative humidity, air pressure, wind speed and cloudiness variables become the most important ones, as we expected. In the context of a regression tree, the deviance is simply the sum of squared errors for the tree. We now plot the tree.

```{r, fig.width=12,fig.height=10}
#| warning: false
plot(tree.precipitation)
text(tree.precipitation,pretty=0)
```

Now we use the cv.tree() function to see whether pruning the tree will improve performance. K-fold cross validation technique is preformed to prune the regression tree.

```{r, fig.width=9,fig.height=5}
#| warning: false
set.seed(1)
cv.precipitation <- cv.tree(tree.precipitation);cv.precipitation

data.frame(Size = cv.precipitation$size, Dev = cv.precipitation$dev) |> 
ggplot(aes(x = Size, y = Dev)) + 
geom_line(color="dodgerblue", size=1) +
geom_point(color="dodgerblue", size=2) +
geom_vline(xintercept = which.min(rev(cv.precipitation$dev)), 
           color="firebrick",  linetype="dashed", size=2) +
theme_bw() 
```

The minimum deviance with less complexity is available where number of terminal nodes is 4. Thus, we can prune the regression tree from 14 to 4 terminal nodes. In this case, the four-node tree is selected by cross-validation. Thus, we can prune the tree, we could do so as follows, using the prune.tree() function:

```{r, fig.width=9,fig.height=6}
#| warning: false
prune.precipitation <- prune.tree(tree.precipitation,best=4)
plot(prune.precipitation)
text(prune.precipitation,pretty=0)
```

In keeping with the cross-validation results, we use the unpruned tree to make predictions on the test set.

```{r, fig.width=9,fig.height=5}
#| warning: false

yhat <- predict(tree.precipitation,newdata=df_tree[-train,])
df_tree.test <- df_tree[-train,"Precipitation"]

plot_test<-
  data.frame(yhat, df_tree.test) |> 
  ggplot(aes(x= yhat, y=df_tree.test)) + 
  theme_bw() +
  geom_point(size=2, alpha=0.5, color="dodgerblue") + 
  geom_abline() + 
  labs(x="Predicted Response",y="True Response") + 
  annotate("text", x=30, y=60, label= 
             paste("MSE is",
             round(mean((yhat - df_tree.test)^2),2)))

plot_test

mse_tree= mse(yhat, df_tree.test)
rmse_tree= rmse(yhat, df_tree.test)
smape_tree= smape(yhat, df_tree.test)
r2_tree= rsq(yhat, df_tree.test)
```

In other words, the test set MSE associated with the regression tree is `r round(mean((yhat - df_tree.test)^2),2)`. The square root of the MSE is therefore around `r round(sqrt(mean((yhat - df_tree.test)^2)),2)`, indicating that this model leads to test predictions that are within around `r round(sqrt(mean((yhat - df_tree.test)^2)),2)` mm of the true median precipitation value for the Mugla Station.

```{r}
#| warning: false
yhat_prune <-predict(prune.precipitation,newdata=df_tree[-train,])

mse_prune_tree= mse(yhat_prune, df_tree.test)
rmse_prune_tree= rmse(yhat_prune, df_tree.test)
smape_prune_tree= smape(yhat_prune, df_tree.test)
r2_prune_tree= rsq(yhat_prune, df_tree.test)
```

The MSE and RMSE for pruned tree are estimated as `r round(mean((yhat_prune - df_tree.test)^2),2)` and `r round(sqrt(mean((yhat_prune - df_tree.test)^2)),2)`, respectively. Due to the nature of regression trees the predictions equal to averages of response variables in training data based on embranchment of the tree. In our example, predictions are available for five and 4 variables for unpruned and pruned cases, respectively.

### Bagging and Random Forests

Here we apply bagging and random forests to the our data, using the randomForest package in R. Recall that bagging is simply a special case of a random forest with m = p. Therefore, the randomForest() function can be used to perform both random forests and bagging. The argument mtry=16 indicates that all 16 predictors should be considered for each split of the tree.

```{r}
set.seed(1)
bag.precipitation <- randomForest(Precipitation ~., data=df_tree, subset=train, mtry=16,importance=TRUE)
bag.precipitation

```

The Random Forest model consists of 500 decision trees. MSE on training data for the last tree is estimated as 71.45367. Percentage of variance in the target variable value of 33.56% indicates that the model explains about 33.56% of the variance in precipitation. The explained variance of 33.56% suggests that the model captures about a third of the variability in precipitation based on the provided predictors. This is a moderate level of explanatory power, indicating that while the model is capturing some of the relationships, there is still a significant portion of variability that it doesn't explain.

```{r, fig.width=9,fig.height=5}
#| warning: false

yhat.bag = predict(bag.precipitation, newdata=df_tree[-train,])

data.frame(yhat.bag, df_tree.test) |> 
ggplot(aes(x= yhat, y=df_tree.test)) + 
theme_bw() +
geom_point(size=2, alpha=0.5, color="dodgerblue") + 
geom_abline() + 
labs(x="Predicted Response",y="True Response") + 
annotate("text", x=40, y=70, label= 
           paste("MSE is",
           round(mean((yhat.bag - df_tree.test)^2),2)))

mse_bag_tree= mse(yhat.bag, df_tree.test)
rmse_bag_tree= rmse(yhat.bag, df_tree.test)
smape_bag_tree= smape(yhat.bag, df_tree.test)
r2_bag_tree= rsq(yhat.bag, df_tree.test)
```

The test set MSE associated with the bagged regression tree is `r round(mean((yhat.bag - df_tree.test)^2),2)`, this is almost 20% lower than that achieved using an optimally-pruned single tree.

Growing a random forest proceeds in exactly the same way, except that we use a smaller value of the mtry argument. By default, randomForest() uses p/3 variables when building a random forest of regression trees, and p^1/2^ variables when building a random forest of classification trees. Here we use mtry = 7

```{r}
#| warning: false
set.seed(1)
rf.precipitation <- randomForest(Precipitation ~., data=df_tree, subset=train, mtry=7,importance=TRUE)
yhat.rf = predict(rf.precipitation, newdata=df_tree[-train,])
round(mean((yhat.rf - df_tree.test)^2),2)

importance(rf.precipitation)

mse_rf_tree= mse(yhat.rf, df_tree.test)
rmse_rf_tree= rmse(yhat.rf, df_tree.test)
smape_rf_tree= smape(yhat.rf, df_tree.test)
r2_rf_tree= rsq(yhat.rf, df_tree.test)
```

The test set MSE is `r round(mean((yhat.rf - df_tree.test)^2),2)`; this indicates that random forests yielded an improvement over bagging in this case. Using the importance() function, we can view the importance of each variable. Two measures of variable importance are reported. The former is based upon the mean decrease of accuracy in predictions on the out of bag samples when a given variable is excluded from the model. The latter is a measure of the total decrease in node impurity that results from splits over that variable, averaged over all trees. In the case of regression trees, the node impurity is measured by the training RSS. Plots of these importance measures can be produced using the varImpPlot() function.

```{r, fig.width=9,fig.height=7}
#| warning: false
varImpPlot(rf.precipitation)
```

The graphs which are variable importance metrics by looking the Percentage Increase in Mean Square Error and Increase in Node Purity explain that how much the model MSE or Node Purity is changed when the specific variable is excluded. In both scenarios increasing these parameters is directly related to importance of the variable which is excluded. The results indicate that across all of the trees considered in the random forest, the air pressure (mb) and the maximum relative humidity (%) are by far the two most important variables.

### Boosting

Here we use the gbm package, and within it the gbm() function, to fit boosted regression trees to the our data set. We run gbm() with the option distribution=gaussian since this is a regression problem, shrinkage parameter/learning rate is taken as 0.03. The argument n.trees=5000 indicates that we want 5000 trees, and the option interaction.depth=6 limits the depth of each tree.

```{r}
#| warning: false
set.seed(1)
boost.precipitation = gbm(Precipitation ~.,
                data = df_tree[train,],
                distribution = "gaussian",
                shrinkage = .01,
                interaction.depth=3,
                n.trees = 500,verbose=F)
 
summary(boost.precipitation)[2]

```

We see that average relative humidity and air pressure variables are the most important variables. Now we can use the boosted model to predict daily precipitation on the test data.

```{r}
#| warning: false
yhat.boost <- predict(boost.precipitation,newdata=df_tree[-train,],n.trees=500)
round(mean((yhat.boost - df_tree.test)^2),2)

mse_boost_tree= mse(yhat.boost, df_tree.test)
rmse_boost_tree= rmse(yhat.boost, df_tree.test)
smape_boost_tree= smape(yhat.boost, df_tree.test)
r2_boost_tree= rsq(yhat.boost, df_tree.test)
```

The test MSE of boosted model obtained is `r round(mean((yhat.boost - df_tree.test)^2),2)` and it is superior to the test MSE for random forests and bagging. Visual comparison of actual and predicted (test) precipitation values are shown in the figure below.

```{r, fig.width=9,fig.height=5}
#| warning: false

data.frame(Date = c(df_n$Date, df_n$Date),
                      Precipitation = c(df_n$Precipitation, 
                                append(rep(NA,length(train)), yhat.boost)),
                      Type = rep(c("Actual", "Predicted"), 
                                 each = length(df_n$Date))) |> 
ggplot(aes(x = Date, y = Precipitation, color = Type)) + 
  geom_line() +
theme_bw() +
scale_color_manual(name=" ",values = c("Actual" = "dodgerblue",
                              "Predicted" = "firebrick"),
                   labels = c("Actual", "Predicted")) +
labs(x="Date",y="Precipitation (mm)") + 
  theme(legend.position = c(.9,.8))+ggtitle("Prediction of Precipitation by using Boosting")
```

# Evaluation Metrics

```{r}
#| warning: false
error_table<- data.frame (
 Statistics = c("MSE","RMSE","SMAPE","R2"), 
 Ridge = c(mse_ridge, rmse_ridge, smape_ridge, r2_ridge), 
 Ridge.cv = c(mse_cv.ridge, rmse_cv.ridge, smape_cv.ridge, r2_cv.ridge), 
 Lasso = c(mse_lasso, rmse_lasso, smape_lasso, r2_lasso), 
 Lasso.cv = c(mse_cv.lasso, rmse_cv.lasso, smape_cv.lasso, r2_cv.lasso), 
 Sarima = c(mse_sarima, rmse_sarima, smape_sarima, r2_sarima), 
 Sarimax = c(mse_sarimax, rmse_sarimax, smape_sarimax, r2_sarimax), 
 SVR = c(mse_svr, rmse_svr, smape_svr, r2_svr), 
 Tree = c(mse_tree, rmse_tree, smape_tree, r2_tree), 
 Prune.Tree = c(mse_prune_tree, rmse_prune_tree, smape_prune_tree, r2_prune_tree), 
 Bagging = c(mse_bag_tree, rmse_bag_tree, smape_bag_tree, r2_bag_tree),
 Random.Forest = c(mse_rf_tree, rmse_rf_tree, smape_rf_tree, r2_rf_tree), 
 Boosting = c(mse_boost_tree, rmse_boost_tree, smape_boost_tree, r2_boost_tree) )

for (i in 2:13) { error_table[,i]<- round(error_table[,i],2) }

t_error_table <- data.frame(t(error_table[,2:13]))
colnames(t_error_table) <- error_table[,1]
t_error_table |>  gt(rownames_to_stub = TRUE)
```

In the provided table, Boosting has the lowest MSE (51.88), indicating that it has the best performance in terms of minimizing the squared differences between predictions and actual values. Random Forest also performs well with a low MSE (54.59). SMAPE is a percentage-based error metric that measures the accuracy of predictions relative to the actual values. It considers the relative difference between predicted and actual values. In the table, Bagging has the lowest SMAPE (1.75), indicating that it has the smallest relative error compared to actual values. Random Forest and Boosting also have low SMAPE values, indicating good accuracy relative to the actual values. R2 ranges from 0 to 1, with higher values indicating better model fit. In the table, Boosting has the highest R2 (0.48), indicating that it explains a significant proportion of the variance in the target variable and has the best overall fit among the models considered. Random Forest also performs well with a high R2 (0.47).

# Results and Conclusion

Eshel and Farrell [@eshel2000] investigated rainfall variability over Eastern Mediterranean and they showed that rainfall is mostly depend on pressure anomalies. Lower air pressure is mostly related with precipitation since mostly frontal systems brings rainfall over Eastern Mediterranean. These frontal systems also means windy storms which comes from over Mediterranean Sea. Similarly, relative humidity is highly related with precipitation since rainfall formation is much easier in saturated air conditions. As everyone might guess cloud is necessary for rainfall production. By the way, dew point temperature means that how much air should be cooled to be saturated without any moisture addition. Thus, closer dew point temperature and air temperature means highly saturated and vice versa. As stated above, relative humidity, cloud coverage, air pressure, dew point temperature, wind direction, wind speed and temperature should be used as predictors while response is precipitation. However, mostly relative humidity and air pressure parameters become our main predictors on modelling precipitation. This situation most probably caused because of predictor's correlation between each other as showed on cor matrix.

We have applied several methodology for modelling daily precipitation in Mugla Station by using multiple predictors. However, some parameters were not used well in some regressions as our expectation such as cloud coverage. Nevertheless, shrinkage methods are used in regression methods for variable selection. SARIMA which is widely used in forecasting time series data, on the other hand, gives us valuable technical information about the data like stationarity, ACF, PACF, seasonality and so forth. Eventually, tree-based methods are used for precipitation modelling.

In summary, based on the provided metrics:

-   Boosting appears to be the best-performing model overall, with the lowest MSE, RMSE, SMAPE and high R2 values.

-   Random Forest also performs well across all metrics, indicating its effectiveness in capturing patterns in the data and making accurate predictions.

-   Other models such as Bagging and Prune. Tree also show competitive performance but are slightly outperformed by Boosting and Random Forest.
